{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Utsav147/Google-Colab-TF-Practice/blob/main/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy"
      ],
      "metadata": {
        "id": "AhWOA8qo6org"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6f86efb",
        "outputId": "3f45e8e4-9e79-4323-ff5c-955feb9bfbe7"
      },
      "source": [
        "try:\n",
        "    import six\n",
        "    print(\"The 'six' library is installed.\")\n",
        "except ImportError:\n",
        "    print(\"The 'six' library is not installed.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 'six' library is installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bHoytMXC7CTn",
        "outputId": "04519023-495b-4d1c-92ae-6aecc11e7d4f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'tensorflow._api.v2.version' from '/usr/local/lib/python3.12/dist-packages/tensorflow/_api/v2/version/__init__.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rank1_tensor=tf.Variable([[[[[[[[\"Test\",\"ok\"],[\"Test\",\"ok\"],[\"Test\",\"ok\"]]]]]]]],tf.string)\n",
        "rank1_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrlHfcqO8Zjq",
        "outputId": "d8865384-303a-4fcb-fd30-43af29d410fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 1, 1, 1, 1, 1, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t=tf.zeros([5,5,5,5])\n",
        "# print(t)"
      ],
      "metadata": {
        "id": "IexWA4Nn_YMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Import Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "print(f\"Keras Version: {keras.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWv7ghSy6-ZQ",
        "outputId": "f9fdb459-68b0-40fd-8f94-839ae07f54dc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.19.0\n",
            "Keras Version: 3.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Generate Historical Weather DataFrame (Past 30 Days)\n",
        "def generate_weather_data(days=30):\n",
        "    \"\"\"\n",
        "    Generate synthetic weather data for past 30 days with realistic patterns\n",
        "    Features: Temperature, Humidity, Pressure, Wind Speed, Cloud Cover, Visibility, Dew Point\n",
        "    \"\"\"\n",
        "    np.random.seed(42)\n",
        "\n",
        "    end_date = datetime.now()\n",
        "    dates = [end_date - timedelta(days=i) for i in range(days-1, -1, -1)]\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for i, date in enumerate(dates):\n",
        "        # Create seasonal temperature pattern\n",
        "        day_of_year = date.timetuple().tm_yday\n",
        "        seasonal_temp = 20 + 10 * np.sin((day_of_year / 365) * 2 * np.pi)\n",
        "\n",
        "        # Add daily variation and random noise\n",
        "        temperature = seasonal_temp + np.random.normal(0, 3)\n",
        "\n",
        "        # Generate correlated weather features\n",
        "        humidity = 60 + np.random.normal(0, 15)\n",
        "        humidity = np.clip(humidity, 20, 100)\n",
        "\n",
        "        pressure = 1013 + np.random.normal(0, 10)\n",
        "\n",
        "        wind_speed = abs(np.random.normal(12, 5))\n",
        "\n",
        "        cloud_cover = np.random.uniform(0, 100)\n",
        "\n",
        "        visibility = 10 + np.random.normal(0, 3)\n",
        "        visibility = np.clip(visibility, 1, 15)\n",
        "\n",
        "        dew_point = temperature - ((100 - humidity) / 5)\n",
        "\n",
        "        data.append({\n",
        "            'Date': date.strftime('%Y-%m-%d'),\n",
        "            'Temperature': round(temperature, 2),\n",
        "            'Humidity': round(humidity, 2),\n",
        "            'Pressure': round(pressure, 2),\n",
        "            'Wind_Speed': round(wind_speed, 2),\n",
        "            'Cloud_Cover': round(cloud_cover, 2),\n",
        "            'Visibility': round(visibility, 2),\n",
        "            'Dew_Point': round(dew_point, 2)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Generate the dataset\n",
        "df = generate_weather_data(30)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"HISTORICAL WEATHER DATA - PAST 30 DAYS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nDataset Shape: {df.shape}\")\n",
        "print(f\"Features: {list(df.columns)}\\n\")\n",
        "print(df.to_string(index=False))\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DATASET STATISTICS\")\n",
        "print(\"=\"*80)\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h-CeESO8X2_",
        "outputId": "f0b9fabc-6aaf-4f1c-dd49-4a0904a7f2ed"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "HISTORICAL WEATHER DATA - PAST 30 DAYS\n",
            "================================================================================\n",
            "\n",
            "Dataset Shape: (30, 8)\n",
            "Features: ['Date', 'Temperature', 'Humidity', 'Pressure', 'Wind_Speed', 'Cloud_Cover', 'Visibility', 'Dew_Point']\n",
            "\n",
            "      Date  Temperature  Humidity  Pressure  Wind_Speed  Cloud_Cover  Visibility  Dew_Point\n",
            "2025-10-03        11.50     57.93   1019.48       19.62        15.60       10.84       3.08\n",
            "2025-10-04        13.05     51.29   1007.75        9.14        52.48        7.23       3.30\n",
            "2025-10-05         4.85     51.57   1002.87       13.57        29.21        7.89      -4.83\n",
            "2025-10-06         3.62     50.56   1018.98       24.80         4.65       11.18      -6.27\n",
            "2025-10-07         6.60     65.64   1006.99       10.54        68.42        6.94      -0.27\n",
            "2025-10-08         9.59     52.00   1012.94       10.85        66.25       11.17      -0.01\n",
            "2025-10-09        10.73     30.60    999.72       12.98        96.96       10.66      -3.15\n",
            "2025-10-10        12.77     44.86    997.17       15.87        35.68        8.39       1.74\n",
            "2025-10-11        11.19     33.55   1016.24       10.07         7.46       11.75      -2.10\n",
            "2025-10-12        12.85     73.41   1020.55       10.96        11.59        8.13       7.53\n",
            "2025-10-13        11.22     74.63   1008.21       11.07        31.10       13.54       6.14\n",
            "2025-10-14         7.56     72.52   1015.97        6.81        71.32        9.77       2.07\n",
            "2025-10-15        11.38     83.07   1012.64       19.82        52.27        8.80       8.00\n",
            "2025-10-16        10.16     38.72   1023.42       16.52        24.93       10.06      -2.10\n",
            "2025-10-17        14.82     52.23   1004.92        9.49        92.97       11.50       5.27\n",
            "2025-10-18        13.91     63.86   1016.15       18.86        89.61       10.53       6.68\n",
            "2025-10-19         8.38     55.09   1009.08        4.68        81.80        2.03      -0.60\n",
            "2025-10-20        11.58     54.07   1010.11       14.26        32.32        9.50       2.39\n",
            "2025-10-21        16.26     62.62   1015.58       11.63        96.24        9.94       8.78\n",
            "2025-10-22         5.64     43.91   1003.07       12.51        50.27        8.70      -5.58\n",
            "2025-10-23        10.15     64.52   1012.65        6.16        98.57       12.30       3.05\n",
            "2025-10-24         7.34     48.37   1020.73        7.99        63.23       14.15      -2.99\n",
            "2025-10-25        12.62     92.86   1003.09        9.17         4.08       15.00      11.19\n",
            "2025-10-26        13.55     60.14   1009.34       15.25        17.44        6.33       5.58\n",
            "2025-10-27         8.25     83.25   1005.17       10.39        92.47        8.93       4.90\n",
            "2025-10-28        12.75     75.66   1018.26       18.82        24.19       15.00       7.88\n",
            "2025-10-29        11.94     71.73   1000.63        5.40        72.60       11.85       6.28\n",
            "2025-10-30        14.89     63.39   1021.47       12.87        69.19        6.35       7.57\n",
            "2025-10-31         7.75     69.85   1003.25       15.94        32.54       12.31       1.72\n",
            "2025-11-01        15.22     66.37   1022.41        7.66        36.77       10.44       8.49\n",
            "\n",
            "================================================================================\n",
            "DATASET STATISTICS\n",
            "================================================================================\n",
            "       Temperature   Humidity     Pressure  Wind_Speed  Cloud_Cover  \\\n",
            "count    30.000000  30.000000    30.000000   30.000000    30.000000   \n",
            "mean     10.737333  60.275667  1011.294667   12.456667    50.740333   \n",
            "std       3.218102  14.821914     7.576598    4.802509    30.969957   \n",
            "min       3.620000  30.600000   997.170000    4.680000     4.080000   \n",
            "25%       8.282500  51.360000  1004.982500    9.250000    26.000000   \n",
            "50%      11.300000  61.380000  1011.375000   11.350000    51.270000   \n",
            "75%      12.830000  71.260000  1017.755000   15.715000    72.280000   \n",
            "max      16.260000  92.860000  1023.420000   24.800000    98.570000   \n",
            "\n",
            "       Visibility  Dew_Point  \n",
            "count   30.000000  30.000000  \n",
            "mean    10.040333   2.791333  \n",
            "std      2.791108   4.745139  \n",
            "min      2.030000  -6.270000  \n",
            "25%      8.467500  -0.517500  \n",
            "50%     10.250000   3.065000  \n",
            "75%     11.687500   6.580000  \n",
            "max     15.000000  11.190000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Prepare Data for LSTM Model\n",
        "# Select features for modeling\n",
        "feature_columns = ['Temperature', 'Humidity', 'Pressure', 'Wind_Speed',\n",
        "                   'Cloud_Cover', 'Visibility', 'Dew_Point']\n",
        "\n",
        "data = df[feature_columns].values\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DATA PREPROCESSING\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Original Data Shape: {data.shape}\")\n",
        "print(f\"Scaled Data Shape: {scaled_data.shape}\")\n",
        "print(f\"\\nFeatures Selected: {feature_columns}\")\n",
        "print(f\"Number of Features: {len(feature_columns)}\")\n",
        "print(f\"\\nScaler Min Values:\\n{scaler.data_min_}\")\n",
        "print(f\"\\nScaler Max Values:\\n{scaler.data_max_}\")\n",
        "\n",
        "def create_sequences(data, seq_length=7):\n",
        "    \"\"\"\n",
        "    Create sequences for LSTM training\n",
        "    Uses past 'seq_length' days to predict next day\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i + seq_length])\n",
        "        y.append(data[i + seq_length])\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Create sequences with 7-day lookback\n",
        "SEQ_LENGTH = 7\n",
        "X, y = create_sequences(scaled_data, SEQ_LENGTH)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"SEQUENCE CREATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Lookback Period: {SEQ_LENGTH} days\")\n",
        "print(f\"X shape: {X.shape} (samples, timesteps, features)\")\n",
        "print(f\"y shape: {y.shape} (samples, features)\")\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "print(f\"\\nTraining set: {X_train.shape}\")\n",
        "print(f\"Testing set: {X_test.shape}\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu_KTxMw8hfZ",
        "outputId": "87c7f29b-e0f3-48e7-c39a-795709bef1e4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DATA PREPROCESSING\n",
            "================================================================================\n",
            "Original Data Shape: (30, 7)\n",
            "Scaled Data Shape: (30, 7)\n",
            "\n",
            "Features Selected: ['Temperature', 'Humidity', 'Pressure', 'Wind_Speed', 'Cloud_Cover', 'Visibility', 'Dew_Point']\n",
            "Number of Features: 7\n",
            "\n",
            "Scaler Min Values:\n",
            "[  3.62  30.6  997.17   4.68   4.08   2.03  -6.27]\n",
            "\n",
            "Scaler Max Values:\n",
            "[  16.26   92.86 1023.42   24.8    98.57   15.     11.19]\n",
            "\n",
            "================================================================================\n",
            "SEQUENCE CREATION\n",
            "================================================================================\n",
            "Lookback Period: 7 days\n",
            "X shape: (23, 7, 7) (samples, timesteps, features)\n",
            "y shape: (23, 7) (samples, features)\n",
            "\n",
            "Training set: (18, 7, 7)\n",
            "Testing set: (5, 7, 7)\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Build, Train and Evaluate LSTM Model\n",
        "def build_lstm_model(input_shape):\n",
        "    \"\"\"\n",
        "    Build LSTM model for multi-feature weather forecasting\n",
        "    Architecture: LSTM layers with dropout for regularization\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        # First LSTM layer with return sequences\n",
        "        LSTM(64, return_sequences=True, input_shape=input_shape),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        # Second LSTM layer\n",
        "        LSTM(32, return_sequences=False),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        # Dense layers\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(input_shape[1])  # Output layer with same features as input\n",
        "    ])\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='mse',\n",
        "        metrics=['mae']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build the model\n",
        "model = build_lstm_model((SEQ_LENGTH, len(feature_columns)))\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"LSTM MODEL ARCHITECTURE\")\n",
        "print(\"=\"*80)\n",
        "model.summary()\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Train the model\n",
        "print(\"\\nTraining the LSTM model...\\n\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=4,\n",
        "    validation_data=(X_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING COMPLETED!\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL EVALUATION METRICS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Test Loss (MSE): {test_loss:.6f}\")\n",
        "print(f\"Test MAE: {test_mae:.6f}\")\n",
        "\n",
        "# Make predictions on test set\n",
        "test_predictions_scaled = model.predict(X_test, verbose=0)\n",
        "test_predictions = scaler.inverse_transform(test_predictions_scaled)\n",
        "y_test_actual = scaler.inverse_transform(y_test)\n",
        "\n",
        "# Calculate MAE for each feature\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"MEAN ABSOLUTE ERROR BY FEATURE\")\n",
        "print(\"=\"*80)\n",
        "for i, feature in enumerate(feature_columns):\n",
        "    mae = np.mean(np.abs(test_predictions[:, i] - y_test_actual[:, i]))\n",
        "    print(f\"{feature:15s}: {mae:.4f}\")\n",
        "\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ycEYNCXT8jCc",
        "outputId": "23600107-e78b-4d8c-b707-766e83a4eb64"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "LSTM MODEL ARCHITECTURE\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m18,432\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m119\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,432</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">119</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,495\u001b[0m (123.03 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,495</span> (123.03 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,495\u001b[0m (123.03 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,495</span> (123.03 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "\n",
            "Training the LSTM model...\n",
            "\n",
            "================================================================================\n",
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - loss: 0.3484 - mae: 0.5234 - val_loss: 0.3136 - val_mae: 0.4930\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.2576 - mae: 0.4446 - val_loss: 0.2114 - val_mae: 0.4002\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.1680 - mae: 0.3452 - val_loss: 0.1262 - val_mae: 0.3134\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0959 - mae: 0.2546 - val_loss: 0.0749 - val_mae: 0.2287\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0970 - mae: 0.2462 - val_loss: 0.0613 - val_mae: 0.2103\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.1073 - mae: 0.2711 - val_loss: 0.0622 - val_mae: 0.2091\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0840 - mae: 0.2335 - val_loss: 0.0668 - val_mae: 0.2282\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0754 - mae: 0.2157 - val_loss: 0.0679 - val_mae: 0.2371\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0926 - mae: 0.2442 - val_loss: 0.0638 - val_mae: 0.2264\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0763 - mae: 0.2303 - val_loss: 0.0613 - val_mae: 0.2145\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0737 - mae: 0.2210 - val_loss: 0.0609 - val_mae: 0.2150\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0837 - mae: 0.2393 - val_loss: 0.0619 - val_mae: 0.2246\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0679 - mae: 0.2217 - val_loss: 0.0678 - val_mae: 0.2402\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0861 - mae: 0.2380 - val_loss: 0.0730 - val_mae: 0.2500\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0736 - mae: 0.2216 - val_loss: 0.0693 - val_mae: 0.2436\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0745 - mae: 0.2250 - val_loss: 0.0631 - val_mae: 0.2245\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0926 - mae: 0.2546 - val_loss: 0.0608 - val_mae: 0.2209\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0701 - mae: 0.2156 - val_loss: 0.0586 - val_mae: 0.2179\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0760 - mae: 0.2259 - val_loss: 0.0575 - val_mae: 0.2150\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0618 - mae: 0.2041 - val_loss: 0.0583 - val_mae: 0.2173\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0759 - mae: 0.2272 - val_loss: 0.0585 - val_mae: 0.2180\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0672 - mae: 0.2154 - val_loss: 0.0613 - val_mae: 0.2255\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0725 - mae: 0.2198 - val_loss: 0.0599 - val_mae: 0.2188\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0688 - mae: 0.2113 - val_loss: 0.0654 - val_mae: 0.2294\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0712 - mae: 0.2233 - val_loss: 0.0656 - val_mae: 0.2320\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0590 - mae: 0.2026 - val_loss: 0.0726 - val_mae: 0.2473\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0719 - mae: 0.2271 - val_loss: 0.0692 - val_mae: 0.2419\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0718 - mae: 0.2116 - val_loss: 0.0641 - val_mae: 0.2312\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0707 - mae: 0.2191 - val_loss: 0.0625 - val_mae: 0.2254\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0710 - mae: 0.2273 - val_loss: 0.0640 - val_mae: 0.2186\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0713 - mae: 0.2165 - val_loss: 0.0690 - val_mae: 0.2314\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0659 - mae: 0.2056 - val_loss: 0.0743 - val_mae: 0.2404\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0791 - mae: 0.2309 - val_loss: 0.0719 - val_mae: 0.2412\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0845 - mae: 0.2410 - val_loss: 0.0708 - val_mae: 0.2419\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0623 - mae: 0.2053 - val_loss: 0.0679 - val_mae: 0.2343\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0620 - mae: 0.2038 - val_loss: 0.0777 - val_mae: 0.2478\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0739 - mae: 0.2186 - val_loss: 0.0704 - val_mae: 0.2369\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0556 - mae: 0.1869 - val_loss: 0.0687 - val_mae: 0.2364\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0608 - mae: 0.2056 - val_loss: 0.0801 - val_mae: 0.2562\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0633 - mae: 0.2120 - val_loss: 0.0943 - val_mae: 0.2761\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0724 - mae: 0.2190 - val_loss: 0.0872 - val_mae: 0.2648\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0699 - mae: 0.2164 - val_loss: 0.0804 - val_mae: 0.2513\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0802 - mae: 0.2348 - val_loss: 0.0663 - val_mae: 0.2216\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0859 - mae: 0.2392 - val_loss: 0.0713 - val_mae: 0.2369\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0627 - mae: 0.2082 - val_loss: 0.0813 - val_mae: 0.2567\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0612 - mae: 0.2076 - val_loss: 0.0953 - val_mae: 0.2735\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0556 - mae: 0.1918 - val_loss: 0.0898 - val_mae: 0.2645\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0554 - mae: 0.1932 - val_loss: 0.0760 - val_mae: 0.2388\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0591 - mae: 0.2014 - val_loss: 0.0773 - val_mae: 0.2416\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0804 - mae: 0.2322 - val_loss: 0.0759 - val_mae: 0.2393\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0633 - mae: 0.2033 - val_loss: 0.0783 - val_mae: 0.2463\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0613 - mae: 0.2043 - val_loss: 0.0858 - val_mae: 0.2596\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0605 - mae: 0.2012 - val_loss: 0.0854 - val_mae: 0.2560\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0685 - mae: 0.2064 - val_loss: 0.0804 - val_mae: 0.2489\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0570 - mae: 0.2018 - val_loss: 0.0817 - val_mae: 0.2551\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0664 - mae: 0.2064 - val_loss: 0.0904 - val_mae: 0.2678\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0610 - mae: 0.2057 - val_loss: 0.0876 - val_mae: 0.2627\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0682 - mae: 0.2153 - val_loss: 0.0751 - val_mae: 0.2341\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0653 - mae: 0.2050 - val_loss: 0.0829 - val_mae: 0.2527\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0599 - mae: 0.1972 - val_loss: 0.0871 - val_mae: 0.2608\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0617 - mae: 0.2016 - val_loss: 0.0859 - val_mae: 0.2610\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0639 - mae: 0.2057 - val_loss: 0.0913 - val_mae: 0.2697\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0534 - mae: 0.1909 - val_loss: 0.0849 - val_mae: 0.2552\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0509 - mae: 0.1854 - val_loss: 0.0749 - val_mae: 0.2319\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0692 - mae: 0.2127 - val_loss: 0.0851 - val_mae: 0.2559\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0666 - mae: 0.2105 - val_loss: 0.0882 - val_mae: 0.2624\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0500 - mae: 0.1858 - val_loss: 0.0808 - val_mae: 0.2497\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0640 - mae: 0.2082 - val_loss: 0.0705 - val_mae: 0.2254\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0588 - mae: 0.1962 - val_loss: 0.0829 - val_mae: 0.2517\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0476 - mae: 0.1798 - val_loss: 0.0864 - val_mae: 0.2606\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0653 - mae: 0.2091 - val_loss: 0.0804 - val_mae: 0.2483\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0509 - mae: 0.1879 - val_loss: 0.0777 - val_mae: 0.2444\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0564 - mae: 0.1944 - val_loss: 0.0858 - val_mae: 0.2611\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0585 - mae: 0.2007 - val_loss: 0.0863 - val_mae: 0.2591\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0518 - mae: 0.1863 - val_loss: 0.0811 - val_mae: 0.2461\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0590 - mae: 0.1899 - val_loss: 0.0769 - val_mae: 0.2382\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0649 - mae: 0.2050 - val_loss: 0.0794 - val_mae: 0.2467\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0609 - mae: 0.2004 - val_loss: 0.0809 - val_mae: 0.2508\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0596 - mae: 0.1996 - val_loss: 0.0820 - val_mae: 0.2518\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0645 - mae: 0.2091 - val_loss: 0.0811 - val_mae: 0.2531\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0585 - mae: 0.1976 - val_loss: 0.0802 - val_mae: 0.2511\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0511 - mae: 0.1872 - val_loss: 0.0759 - val_mae: 0.2386\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0588 - mae: 0.1988 - val_loss: 0.0761 - val_mae: 0.2411\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0599 - mae: 0.2030 - val_loss: 0.0753 - val_mae: 0.2377\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0655 - mae: 0.2034 - val_loss: 0.0773 - val_mae: 0.2329\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0438 - mae: 0.1664 - val_loss: 0.0816 - val_mae: 0.2450\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0569 - mae: 0.1890 - val_loss: 0.0810 - val_mae: 0.2477\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0551 - mae: 0.1956 - val_loss: 0.0808 - val_mae: 0.2519\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0692 - mae: 0.2127 - val_loss: 0.0808 - val_mae: 0.2522\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0619 - mae: 0.2003 - val_loss: 0.0785 - val_mae: 0.2386\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0657 - mae: 0.2087 - val_loss: 0.0819 - val_mae: 0.2446\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0541 - mae: 0.1829 - val_loss: 0.0799 - val_mae: 0.2464\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0568 - mae: 0.1895 - val_loss: 0.0798 - val_mae: 0.2490\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0587 - mae: 0.1961 - val_loss: 0.0791 - val_mae: 0.2440\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0551 - mae: 0.1906 - val_loss: 0.0728 - val_mae: 0.2250\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0635 - mae: 0.2013 - val_loss: 0.0775 - val_mae: 0.2315\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0567 - mae: 0.1899 - val_loss: 0.0830 - val_mae: 0.2498\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0522 - mae: 0.1848 - val_loss: 0.0830 - val_mae: 0.2508\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0560 - mae: 0.1977 - val_loss: 0.0802 - val_mae: 0.2444\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0585 - mae: 0.1988 - val_loss: 0.0776 - val_mae: 0.2381\n",
            "\n",
            "================================================================================\n",
            "TRAINING COMPLETED!\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODEL EVALUATION METRICS\n",
            "================================================================================\n",
            "Test Loss (MSE): 0.077562\n",
            "Test MAE: 0.238125\n",
            "\n",
            "================================================================================\n",
            "MEAN ABSOLUTE ERROR BY FEATURE\n",
            "================================================================================\n",
            "Temperature    : 2.6807\n",
            "Humidity       : 7.8759\n",
            "Pressure       : 10.2629\n",
            "Wind_Speed     : 4.4769\n",
            "Cloud_Cover    : 25.5467\n",
            "Visibility     : 3.1429\n",
            "Dew_Point      : 3.5293\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Predict Today's Weather\n",
        "# Use the last 7 days to predict today\n",
        "last_sequence = scaled_data[-SEQ_LENGTH:]\n",
        "last_sequence_reshaped = last_sequence.reshape(1, SEQ_LENGTH, len(feature_columns))\n",
        "\n",
        "# Predict today's weather\n",
        "today_prediction_scaled = model.predict(last_sequence_reshaped, verbose=0)\n",
        "today_prediction = scaler.inverse_transform(today_prediction_scaled)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TODAY'S WEATHER PREDICTION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Prediction Date: {datetime.now().strftime('%Y-%m-%d')}\\n\")\n",
        "\n",
        "for i, feature in enumerate(feature_columns):\n",
        "    unit = \"°C\" if feature == \"Temperature\" or feature == \"Dew_Point\" else \\\n",
        "           \"%\" if feature == \"Humidity\" or feature == \"Cloud_Cover\" else \\\n",
        "           \"hPa\" if feature == \"Pressure\" else \\\n",
        "           \"km/h\" if feature == \"Wind_Speed\" else \"km\"\n",
        "    print(f\"{feature:15s}: {today_prediction[0][i]:8.2f} {unit}\")\n",
        "\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BFoq-Gi8oHV",
        "outputId": "5234361c-f044-408e-c355-73672c8b9c87"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "TODAY'S WEATHER PREDICTION\n",
            "================================================================================\n",
            "Prediction Date: 2025-11-01\n",
            "\n",
            "Temperature    :    10.27 °C\n",
            "Humidity       :    54.25 %\n",
            "Pressure       :  1008.14 hPa\n",
            "Wind_Speed     :    10.07 km/h\n",
            "Cloud_Cover    :    66.29 %\n",
            "Visibility     :     8.40 km\n",
            "Dew_Point      :     1.83 °C\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Predict Next 7 Days Weather\n",
        "def predict_next_days(model, last_sequence, scaler, days=7):\n",
        "    \"\"\"\n",
        "    Predict weather for the next 'days' days\n",
        "    Uses iterative prediction: each prediction becomes input for next\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    current_sequence = last_sequence.copy()\n",
        "\n",
        "    for i in range(days):\n",
        "        # Reshape for prediction\n",
        "        current_input = current_sequence.reshape(1, SEQ_LENGTH, len(feature_columns))\n",
        "\n",
        "        # Predict next day\n",
        "        next_pred_scaled = model.predict(current_input, verbose=0)\n",
        "        next_pred = scaler.inverse_transform(next_pred_scaled)\n",
        "\n",
        "        predictions.append(next_pred[0])\n",
        "\n",
        "        # Update sequence: remove oldest, add newest\n",
        "        current_sequence = np.vstack([current_sequence[1:], next_pred_scaled[0]])\n",
        "\n",
        "    return np.array(predictions)\n",
        "\n",
        "# Predict next 7 days\n",
        "print(\"=\"*80)\n",
        "print(\"GENERATING 7-DAY FORECAST...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "future_predictions = predict_next_days(model, scaled_data[-SEQ_LENGTH:], scaler, days=7)\n",
        "\n",
        "# Create dataframe for predictions\n",
        "future_dates = [(datetime.now() + timedelta(days=i+1)).strftime('%Y-%m-%d') for i in range(7)]\n",
        "predictions_df = pd.DataFrame(future_predictions, columns=feature_columns)\n",
        "predictions_df.insert(0, 'Date', future_dates)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"NEXT 7 DAYS WEATHER FORECAST\")\n",
        "print(\"=\"*80)\n",
        "print(predictions_df.to_string(index=False))\n",
        "print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Hy6A9gH8t5N",
        "outputId": "e38d9f08-ff50-4272-f66a-3b45bcc83c0c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "GENERATING 7-DAY FORECAST...\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "NEXT 7 DAYS WEATHER FORECAST\n",
            "================================================================================\n",
            "      Date  Temperature  Humidity    Pressure  Wind_Speed  Cloud_Cover  Visibility  Dew_Point\n",
            "2025-11-02    10.274011 54.246628 1008.139648   10.065694    66.290527    8.396559   1.833741\n",
            "2025-11-03    10.674711 58.760124 1009.852661   10.437902    65.382919    9.156222   2.545881\n",
            "2025-11-04    10.808354 56.348705 1008.940308   10.418057    73.231812    8.646022   2.450877\n",
            "2025-11-05    10.141576 58.774776 1009.012024    9.635486    65.555328    9.391857   2.121711\n",
            "2025-11-06    10.275707 57.153996 1008.829346    9.913975    64.260170    9.078058   2.106883\n",
            "2025-11-07    10.266674 57.352142 1008.919800    9.996714    60.194740    9.002041   2.057552\n",
            "2025-11-08     9.877362 59.339069 1008.579712    9.240508    62.422386    9.610801   2.019758\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Summary and Model Information\n",
        "print(\"=\"*80)\n",
        "print(\"WEATHER FORECASTING MODEL SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nModel Type: LSTM (Long Short-Term Memory) Neural Network\")\n",
        "print(f\"Architecture: 2 LSTM layers (64, 32 units) + Dense layers\")\n",
        "print(f\"Sequence Length: {SEQ_LENGTH} days lookback\")\n",
        "print(f\"Features Used: {len(feature_columns)}\")\n",
        "print(f\"  - {', '.join(feature_columns)}\")\n",
        "print(f\"\\nTraining Data: {len(df)} days of historical weather data\")\n",
        "print(f\"Training Epochs: 100\")\n",
        "print(f\"Batch Size: 4\")\n",
        "print(f\"Optimizer: Adam (learning rate: 0.001)\")\n",
        "print(f\"Loss Function: Mean Squared Error (MSE)\")\n",
        "print(f\"Evaluation Metric: Mean Absolute Error (MAE)\")\n",
        "print(f\"\\nPredictions Generated:\")\n",
        "print(f\"  ✓ Today's weather prediction\")\n",
        "print(f\"  ✓ Next 7 days forecast\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"WHY LSTM FOR WEATHER FORECASTING?\")\n",
        "print(\"=\"*80)\n",
        "print(\"✓ Excellent for time series data and sequential patterns\")\n",
        "print(\"✓ Captures temporal dependencies in weather patterns\")\n",
        "print(\"✓ Handles multiple features simultaneously (7 features)\")\n",
        "print(\"✓ Remembers long-term patterns through cell states\")\n",
        "print(\"✓ Can learn complex non-linear relationships\")\n",
        "print(\"✓ Suitable for multi-step ahead forecasting\")\n",
        "print(\"✓ Resistant to vanishing gradient problem\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Display comparison: Last 3 days historical vs Next 3 days predicted\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TEMPERATURE TREND COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nLast 3 Days (Historical):\")\n",
        "print(df[['Date', 'Temperature']].tail(3).to_string(index=False))\n",
        "print(\"\\nNext 3 Days (Predicted):\")\n",
        "print(predictions_df[['Date', 'Temperature']].head(3).to_string(index=False))\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TZFODpj8yXU",
        "outputId": "5c3d2b38-0c11-4c33-b897-37fdc1821c54"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "WEATHER FORECASTING MODEL SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Model Type: LSTM (Long Short-Term Memory) Neural Network\n",
            "Architecture: 2 LSTM layers (64, 32 units) + Dense layers\n",
            "Sequence Length: 7 days lookback\n",
            "Features Used: 7\n",
            "  - Temperature, Humidity, Pressure, Wind_Speed, Cloud_Cover, Visibility, Dew_Point\n",
            "\n",
            "Training Data: 30 days of historical weather data\n",
            "Training Epochs: 100\n",
            "Batch Size: 4\n",
            "Optimizer: Adam (learning rate: 0.001)\n",
            "Loss Function: Mean Squared Error (MSE)\n",
            "Evaluation Metric: Mean Absolute Error (MAE)\n",
            "\n",
            "Predictions Generated:\n",
            "  ✓ Today's weather prediction\n",
            "  ✓ Next 7 days forecast\n",
            "\n",
            "================================================================================\n",
            "WHY LSTM FOR WEATHER FORECASTING?\n",
            "================================================================================\n",
            "✓ Excellent for time series data and sequential patterns\n",
            "✓ Captures temporal dependencies in weather patterns\n",
            "✓ Handles multiple features simultaneously (7 features)\n",
            "✓ Remembers long-term patterns through cell states\n",
            "✓ Can learn complex non-linear relationships\n",
            "✓ Suitable for multi-step ahead forecasting\n",
            "✓ Resistant to vanishing gradient problem\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "TEMPERATURE TREND COMPARISON\n",
            "================================================================================\n",
            "\n",
            "Last 3 Days (Historical):\n",
            "      Date  Temperature\n",
            "2025-10-30        14.89\n",
            "2025-10-31         7.75\n",
            "2025-11-01        15.22\n",
            "\n",
            "Next 3 Days (Predicted):\n",
            "      Date  Temperature\n",
            "2025-11-02    10.274011\n",
            "2025-11-03    10.674711\n",
            "2025-11-04    10.808354\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"weather.csv\")\n",
        "\n",
        "# Create lag features\n",
        "def create_lag_features(data, col, lags=3):\n",
        "    for i in range(1, lags + 1):\n",
        "        data[f\"{col}_t-{i}\"] = data[col].shift(i)\n",
        "    return data\n",
        "\n",
        "# Apply lagging on important features\n",
        "for feature in ['temp', 'humidity', 'pressure', 'wind_speed']:\n",
        "    df = create_lag_features(df, feature, lags=3)\n",
        "\n",
        "# Drop rows having NaN after lag\n",
        "df = df.dropna()\n",
        "\n",
        "# Select features and target\n",
        "X = df.drop(columns=['date', 'target_temp_next_day'])\n",
        "y = df['target_temp_next_day']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "# Build XGBoost model\n",
        "model = XGBRegressor(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"MAE:\", mae)\n",
        "\n",
        "# Predict next day's temperature\n",
        "latest_row = X.tail(1)\n",
        "next_temp = model.predict(latest_row)\n",
        "print(\"Predicted next day temperature:\", next_temp[0])\n"
      ],
      "metadata": {
        "id": "EISc2rV182cz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}